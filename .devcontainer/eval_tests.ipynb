{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from typing import Optional, Dict, Any, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f391cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://host.docker.internal:8000\"\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"admin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4312cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Connecting & Authenticating to http://host.docker.internal:8000 ---\n",
      "‚úÖ Login Successful\n",
      "User: admin\n",
      "Token (first 20 chars): eyJhbGciOiJIUzI1NiIs...\n",
      "\n",
      "--- 2. Testing Connection (Health Check) ---\n",
      "‚úÖ Health Check Passed\n",
      "{'status': 'healthy'}\n",
      "\n",
      "--- 3. Fetching Available Models ---\n",
      "‚úÖ Found 3 models:\n",
      " - Unknown ID: deepseek-v3.2:cloud\n",
      " - Unknown ID: mistral-large-3:675b-cloud\n",
      " - Unknown ID: kimi-k2-thinking:cloud\n"
     ]
    }
   ],
   "source": [
    "# Create a client session\n",
    "client = httpx.Client(base_url=BASE_URL, timeout=30.0)\n",
    "\n",
    "try:\n",
    "    print(f\"--- 1. Connecting & Authenticating to {BASE_URL} ---\")\n",
    "    \n",
    "    # Login\n",
    "    login_response = client.post(\n",
    "        \"/api/auth/login\",\n",
    "        json={\"username\": USERNAME, \"password\": PASSWORD, \"rememberMe\": False}\n",
    "    )\n",
    "    login_response.raise_for_status()\n",
    "    \n",
    "    # Extract token and set headers for future requests\n",
    "    login_data = login_response.json()\n",
    "    token = login_data[\"token\"]\n",
    "    client.headers.update({\"Authorization\": f\"Bearer {token}\"})\n",
    "    \n",
    "    print(\"‚úÖ Login Successful\")\n",
    "    print(f\"User: {login_data.get('user', {}).get('username')}\")\n",
    "    print(f\"Token (first 20 chars): {token[:20]}...\")\n",
    "\n",
    "    print(\"\\n--- 2. Testing Connection (Health Check) ---\")\n",
    "    \n",
    "    # Simple health check (often /api/health or /health)\n",
    "    # Based on your swagger, it is likely /api/health\n",
    "    try:\n",
    "        health = client.get(\"/api/health\")\n",
    "        if health.status_code == 200:\n",
    "            print(\"‚úÖ Health Check Passed\")\n",
    "            print(health.json())\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Health Check returned status: {health.status_code}\")\n",
    "    except httpx.HTTPStatusError:\n",
    "        print(\"‚ö†Ô∏è Health Check failed or endpoint not found.\")\n",
    "\n",
    "    print(\"\\n--- 3. Fetching Available Models ---\")\n",
    "    \n",
    "    # Get Models\n",
    "    models_response = client.get(\"/api/models\")\n",
    "    models_response.raise_for_status()\n",
    "    models = models_response.json()\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(models)} models:\")\n",
    "    for m in models:\n",
    "        # Adjust 'id' or 'name' based on the actual response structure\n",
    "        print(f\" - {m.get('id', 'Unknown ID')}: {m.get('name', 'No Name')}\")\n",
    "\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(f\"‚ùå HTTP Error: {e.response.status_code} - {e.response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection Error: {e}\")\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "BASE_URL = \"http://host.docker.internal:8000\"\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"admin\"\n",
    "QUESTION = \"How is the chair of Food Standards Scotland appointed\"\n",
    "\n",
    "def run_debug_script():\n",
    "    print(f\"Targeting: {BASE_URL}\")\n",
    "    \n",
    "    with httpx.Client(base_url=BASE_URL, timeout=60.0) as client:\n",
    "        \n",
    "        # 1. Login & Auth\n",
    "        print(\"\\nüîê Logging in...\")\n",
    "        try:\n",
    "            login_resp = client.post(\"/api/auth/login\", \n",
    "                                   json={\"username\": USERNAME, \"password\": PASSWORD})\n",
    "            login_resp.raise_for_status()\n",
    "            token = login_resp.json()[\"token\"]\n",
    "            client.headers.update({\"Authorization\": f\"Bearer {token}\"})\n",
    "            print(\"‚úÖ Login successful\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Login failed: {e}\")\n",
    "            return\n",
    "\n",
    "        # 2. Get Models\n",
    "        print(\"\\nü§ñ Fetching models...\")\n",
    "        models_resp = client.get(\"/api/models\")\n",
    "        models_resp.raise_for_status()\n",
    "        models = models_resp.json()\n",
    "        \n",
    "        # Select a model\n",
    "        if len(models) > 1:\n",
    "            model_id = models[1].get(\"id\") or models[1].get(\"name\")\n",
    "        else:\n",
    "            model_id = models[0].get(\"id\") or models[0].get(\"name\")\n",
    "            \n",
    "        print(f\"üëâ Using model: {model_id}\")\n",
    "\n",
    "        # 3. Generate Answer AND Capture Retrieval Context (Streaming)\n",
    "        print(f\"\\nüí¨ Sending Query: '{QUESTION}'\")\n",
    "        print(\"‚è≥ Streaming answer...\\n\")\n",
    "        \n",
    "        chat_payload = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": QUESTION}],\n",
    "            \"model\": model_id,\n",
    "            \"deep_research\": True  # Important: enables tool calling!\n",
    "        }\n",
    "        \n",
    "        actual_output = \"\"\n",
    "        retrieval_context = []  # Capture context during streaming\n",
    "        \n",
    "        # Connect to stream\n",
    "        with client.stream(\"POST\", \"/api/chat\", json=chat_payload) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Iterate over SSE lines\n",
    "            for line in response.iter_lines():\n",
    "                if line.startswith(\"data: \"):\n",
    "                    try:\n",
    "                        json_str = line[6:]\n",
    "                        if not json_str.strip() or json_str == \"[DONE]\":\n",
    "                            continue\n",
    "                            \n",
    "                        data = json.loads(json_str)\n",
    "                        event_type = data.get(\"type\")\n",
    "                        \n",
    "                        # Capture streaming tokens\n",
    "                        if event_type == \"token\":\n",
    "                            chunk = data.get(\"content\", \"\")\n",
    "                            actual_output += chunk\n",
    "                            print(chunk, end=\"\", flush=True)\n",
    "                        \n",
    "                        # Capture tool calls\n",
    "                        elif event_type == \"tool_call\":\n",
    "                            tool_name = data.get(\"tool_name\", \"unknown\")\n",
    "                            arguments = data.get(\"arguments\", {})\n",
    "                            print(f\"\\n\\nüîß [TOOL CALL: {tool_name}]\")\n",
    "                            print(f\"   Arguments: {json.dumps(arguments, indent=2)}\")\n",
    "                        \n",
    "                        # Capture tool results (THIS IS THE RETRIEVAL CONTEXT!)\n",
    "                        elif event_type == \"tool_result\":\n",
    "                            tool_name = data.get(\"tool_name\", \"unknown\")\n",
    "                            result = data.get(\"result\", \"\")\n",
    "                            \n",
    "                            if result and result.strip():\n",
    "                                retrieval_context.append(result)\n",
    "                                \n",
    "                                print(f\"\\n\\nüì• [TOOL RESULT: {tool_name}]\")\n",
    "                                print(f\"   Retrieved {len(result)} characters\")\n",
    "                                preview = result[:200] + \"...\" if len(result) > 200 else result\n",
    "                                print(f\"   Preview: {preview}\\n\")\n",
    "                        \n",
    "                        # Capture final result (if provided)\n",
    "                        elif event_type == \"result\":\n",
    "                            final_message = data.get(\"message\", \"\")\n",
    "                            if final_message and not actual_output:\n",
    "                                actual_output = final_message\n",
    "                            print(\"\\n\\n‚úÖ Response complete\")\n",
    "                        \n",
    "                        # Handle errors\n",
    "                        elif event_type == \"error\":\n",
    "                            error_msg = data.get(\"error\", \"Unknown error\")\n",
    "                            print(f\"\\n\\n‚ùå Error: {error_msg}\")\n",
    "                            \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"\\n‚ö†Ô∏è  JSON decode error: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        print(\"\\n\\n\" + \"=\"*80)\n",
    "\n",
    "        # 4. Verify we got context\n",
    "        print(f\"\\nüìä CAPTURE SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚úÖ Generated output: {len(actual_output)} characters\")\n",
    "        print(f\"‚úÖ Retrieved context: {len(retrieval_context)} documents\")\n",
    "        \n",
    "        if not retrieval_context:\n",
    "            print(\"\\n‚ö†Ô∏è  WARNING: No retrieval context captured!\")\n",
    "            print(\"   This could mean:\")\n",
    "            print(\"   - deep_research was not enabled\")\n",
    "            print(\"   - No tools were called for this query\")\n",
    "            print(\"   - Tool results were empty\")\n",
    "        else:\n",
    "            print(f\"\\nüìö Context Documents:\")\n",
    "            for i, ctx in enumerate(retrieval_context, 1):\n",
    "                print(f\"\\n   Document {i}: {len(ctx)} chars\")\n",
    "                print(f\"   Preview: {ctx[:150]}...\")\n",
    "\n",
    "        # 5. Prepare DeepEval Test Case\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üß™ DEEPEVAL TEST CASE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        test_case = LLMTestCase(\n",
    "            input=QUESTION,\n",
    "            actual_output=actual_output,\n",
    "            retrieval_context=retrieval_context\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nINPUT:\")\n",
    "        print(f\"{test_case.input}\")\n",
    "        \n",
    "        print(f\"\\nACTUAL OUTPUT ({len(test_case.actual_output)} chars):\")\n",
    "        print(f\"{test_case.actual_output[:300]}...\")\n",
    "        \n",
    "        print(f\"\\nRETRIEVAL CONTEXT ({len(test_case.retrieval_context)} documents):\")\n",
    "        for i, ctx in enumerate(test_case.retrieval_context, 1):\n",
    "            print(f\"\\n--- Document {i} ({len(ctx)} chars) ---\")\n",
    "            print(f\"{ctx[:200]}...\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ Test case ready for evaluation!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"  1. from deepeval.metrics import FaithfulnessMetric\")\n",
    "        print(\"  2. metric = FaithfulnessMetric(threshold=0.7, model='gpt-4')\")\n",
    "        print(\"  3. metric.measure(test_case)\")\n",
    "        print(\"  4. print(metric.score, metric.reason)\")\n",
    "        \n",
    "        return test_case\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_case = run_debug_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b8526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ToolCall\n",
    "\n",
    "BASE_URL = \"http://host.docker.internal:8000\"\n",
    "AUTH_DATA = {\"username\": \"admin\", \"password\": \"admin\"}\n",
    "\n",
    "def get_authenticated_client():\n",
    "    \"\"\"\n",
    "    Creates and authenticates a client. \n",
    "    We do NOT use 'with' inside here so the caller can manage the lifecycle.\n",
    "    \"\"\"\n",
    "    client = httpx.Client(base_url=BASE_URL, timeout=None)\n",
    "    \n",
    "    print(\"üîê Logging in...\")\n",
    "    try:\n",
    "        # Perform login\n",
    "        resp = client.post(\"/api/auth/login\", json=AUTH_DATA)\n",
    "        resp.raise_for_status()\n",
    "        \n",
    "        token = resp.json()[\"token\"]\n",
    "        client.headers.update({\"Authorization\": f\"Bearer {token}\"})\n",
    "        print(\"‚úÖ Login successful\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        client.close()\n",
    "        print(f\"‚ùå Authentication failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def capture_legal_test_case(client, question, model_id, deep_research=False):\n",
    "    \"\"\"Executes the query and captures context for DeepEval.\"\"\"\n",
    "    \n",
    "    chat_payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"model\": model_id,\n",
    "        \"deep_research\": deep_research,\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    actual_output = \"\"\n",
    "    retrieval_context = []\n",
    "    tools_used = []\n",
    "\n",
    "    print(f\"‚è≥ Processing legal research for: '{question}'\")\n",
    "\n",
    "    with client.stream(\"POST\", \"/api/system/chat\", json=chat_payload) as response:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        for line in response.iter_lines():\n",
    "            if not line.startswith(\"data: \"): continue\n",
    "            \n",
    "            json_str = line[6:]\n",
    "            if json_str == \"[DONE]\": break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "                event_type = data.get(\"type\")\n",
    "\n",
    "                if event_type == \"tool_start\":\n",
    "                    tool_name = data.get(\"tool\")\n",
    "                    if tool_name:\n",
    "                        tools_used.append(ToolCall(name=tool_name))\n",
    "\n",
    "                # Capture LLM Tokens\n",
    "                if event_type == \"token\":\n",
    "                    chunk = data.get(\"content\", \"\")\n",
    "                    actual_output += chunk\n",
    "                \n",
    "                # Inside your capture loop:\n",
    "                elif event_type == \"api_call_end\":\n",
    "                    resp_body = data.get(\"response\", {})\n",
    "                    \n",
    "                    # PRIORITY 1: Full Legislation Text (The most important for Faithfulness)\n",
    "                    if \"full_text\" in resp_body:\n",
    "                        legislation_title = resp_body.get(\"legislation\", {}).get(\"title\", \"Unknown Act\")\n",
    "                        content = resp_body[\"full_text\"]\n",
    "                        retrieval_context.append(f\"Source: {legislation_title}\\nContent: {content}\")\n",
    "                    \n",
    "                    # PRIORITY 2: Search Results (If full text wasn't fetched yet)\n",
    "                    elif \"results\" in resp_body:\n",
    "                        for item in resp_body[\"results\"]:\n",
    "                            title = item.get(\"title\", \"Unknown Source\")\n",
    "                            desc = item.get(\"description\", \"\")\n",
    "                            if desc:\n",
    "                                retrieval_context.append(f\"Source: {title}\\nSummary: {desc}\")\n",
    "\n",
    "                elif event_type == \"tool_result\":\n",
    "                    # The 'delegate_research' tool result provides a summary of the agent's findings.\n",
    "                    # This is useful for 'Answer Relevancy' but 'Faithfulness' needs the raw full_text above.\n",
    "                    res_text = data.get(\"result\", \"\")\n",
    "                    if res_text:\n",
    "                        retrieval_context.append(f\"Agent Summary: {res_text}\")\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    # Return the formatted test case for DeepEval\n",
    "    return LLMTestCase(\n",
    "        input=question,\n",
    "        actual_output=actual_output,\n",
    "        tools_called=tools_used,\n",
    "        retrieval_context=list(dict.fromkeys(retrieval_context)) # Deduplicate\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase, ToolCall\n",
    "import json\n",
    "\n",
    "def capture_with_audit(client, question, model_id, deep_research=False):\n",
    "    chat_payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"model\": model_id,\n",
    "        \"deep_research\": deep_research,\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    print(f\"‚è≥ Auditing research for: '{question}'\")\n",
    "    \n",
    "    actual_output = \"\"\n",
    "    retrieval_context = []\n",
    "    tools_captured = []\n",
    "    \n",
    "    # --- STATE MACHINE VARIABLES ---\n",
    "    # We use these to \"hold\" data as we stream through the events\n",
    "    current_tool = {} \n",
    "\n",
    "    with client.stream(\"POST\", \"/api/system/chat\", json=chat_payload) as response:\n",
    "        for line in response.iter_lines():\n",
    "            if not line.startswith(\"data: \"): continue\n",
    "            json_str = line[6:]\n",
    "            if json_str == \"[DONE]\": break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "                event_type = data.get(\"type\")\n",
    "\n",
    "                # 1. Capture the Answer Text\n",
    "                if event_type == \"token\":\n",
    "                    actual_output += data.get(\"content\", \"\")\n",
    "\n",
    "                # 2. START A NEW TOOL\n",
    "                elif event_type == \"tool_start\":\n",
    "                    # If we were tracking a previous tool, save it (failsafe)\n",
    "                    if current_tool.get(\"name\"):\n",
    "                         tools_captured.append(ToolCall(\n",
    "                             name=current_tool[\"name\"],\n",
    "                             input_parameters=current_tool.get(\"input_parameters\", {}),\n",
    "                             output=current_tool.get(\"output\", \"No output captured\")\n",
    "                         ))\n",
    "                    \n",
    "                    # Start fresh\n",
    "                    current_tool = {\n",
    "                        \"name\": data.get(\"tool\"),\n",
    "                        \"input_parameters\": {},\n",
    "                        \"output\": None\n",
    "                    }\n",
    "\n",
    "                # 3. CAPTURE INPUTS (The API Payload)\n",
    "                elif event_type == \"api_call_start\":\n",
    "                    # This event contains the actual query sent to the legal database\n",
    "                    if current_tool:\n",
    "                        current_tool[\"input_parameters\"] = data.get(\"payload\", {})\n",
    "\n",
    "                # 4. CAPTURE OUTPUTS (The API Response)\n",
    "                elif event_type == \"api_call_end\":\n",
    "                    resp = data.get(\"response\", {})\n",
    "                    \n",
    "                    # A: Save for Faithfulness (Context)\n",
    "                    if \"full_text\" in resp:\n",
    "                         retrieval_context.append(resp[\"full_text\"])\n",
    "                    elif \"results\" in resp:\n",
    "                        for r in resp[\"results\"]:\n",
    "                            retrieval_context.append(r.get(\"description\", \"\"))\n",
    "                            \n",
    "                    # B: Save for Auditing (Tool Output)\n",
    "                    if current_tool:\n",
    "                        # Convert complex JSON to string for the ToolCall object\n",
    "                        current_tool[\"output\"] = str(resp)[:1000] + \"...\" # Truncate if huge\n",
    "\n",
    "                # 5. CLOSE THE TOOL\n",
    "                elif event_type == \"tool_end\":\n",
    "                    if current_tool.get(\"name\"):\n",
    "                        # If we missed the api_call_end, try to use the generic result\n",
    "                        if not current_tool[\"output\"]:\n",
    "                            current_tool[\"output\"] = str(data.get(\"result\", \"\"))\n",
    "                        \n",
    "                        # Create the DeepEval Object\n",
    "                        tools_captured.append(ToolCall(\n",
    "                            name=current_tool[\"name\"],\n",
    "                            input_parameters=current_tool[\"input_parameters\"],\n",
    "                            output=current_tool[\"output\"]\n",
    "                        ))\n",
    "                        current_tool = {} # Reset\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    return LLMTestCase(\n",
    "        input=question,\n",
    "        actual_output=actual_output,\n",
    "        retrieval_context=list(dict.fromkeys(retrieval_context)),\n",
    "        tools_called=tools_captured\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def inspect_tool_outputs(client, question, model_id):\n",
    "    \"\"\"\n",
    "    A diagnostic function to print the raw JSON structure of LEX tool returns.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"model\": model_id,\n",
    "        \"deep_research\": False, # Switch off web/deep research as requested\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüîç INSPECTING RAW TOOL RESPONSES FOR: '{question}'\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    with client.stream(\"POST\", \"/api/system/chat\", json=payload) as response:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        for line in response.iter_lines():\n",
    "            if not line.startswith(\"data: \"):\n",
    "                continue\n",
    "            \n",
    "            json_str = line[6:]\n",
    "            if json_str == \"[DONE]\":\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "                event_type = data.get(\"type\")\n",
    "\n",
    "                # Focus on the events that actually contain retrieved legal data\n",
    "                if event_type in [\"api_call_end\", \"tool_result\"]:\n",
    "                    print(f\"\\nüì¶ EVENT TYPE: {event_type}\")\n",
    "                    # Pretty-print the whole JSON block so you can see the keys\n",
    "                    print(json.dumps(data, indent=4))\n",
    "                    print(\"-\" * 30)\n",
    "                \n",
    "                # Optionally print tokens just to see progress\n",
    "                elif event_type == \"token\":\n",
    "                    print(\".\", end=\"\", flush=True)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    print(\"\\n\\n‚úÖ Inspection Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9137eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # The client is created and authenticated here\n",
    "    client = get_authenticated_client()\n",
    "    \n",
    "    try:\n",
    "        legal_query = \"How is the chair of Food Standards Scotland appointed\"\n",
    "        # Pass the already open client to your capture function\n",
    "        \n",
    "        #test_case = capture_legal_test_case(client, legal_query, \"mistral-large-3:675b-cloud\")\n",
    "        #test_case = capture_with_audit(client, legal_query, \"mistral-large-3:675b-cloud\")\n",
    "        inspect_case = inspect_tool_outputs(client, legal_query, \"mistral-large-3:675b-cloud\")\n",
    "    finally:\n",
    "        # Crucial: Always close the client when finished to free up Docker resources\n",
    "        client.close()\n",
    "        print(\"üîå Client connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
